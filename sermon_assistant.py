import streamlit as st
import pandas as pd
import requests 
import google.generativeai as genai
import json
import re
import time
import numpy as np
from urllib.parse import urlparse, parse_qs
from pathlib import Path
import io

# Google Drive API
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload

# =============================================================================
# ğŸ” ë³´ì•ˆ ì„¤ì • (Security Setup)
# =============================================================================

try:
    NOTION_API_KEY = st.secrets["NOTION_API_KEY"]
    NOTION_DATABASE_ID = st.secrets["NOTION_DATABASE_ID"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    GDRIVE_FOLDER_ID = st.secrets["GDRIVE_FOLDER_ID"]
    GDRIVE_FILE_ID = st.secrets["GDRIVE_FILE_ID"]  # íŒŒì¼ ID ì§ì ‘ ì§€ì •
    
    # ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ (secrets.tomlì—ì„œ ë¡œë“œ)
    GDRIVE_SERVICE_ACCOUNT = st.secrets["GDRIVE_SERVICE_ACCOUNT"]
except (FileNotFoundError, KeyError) as e:
    st.error(f"âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    st.info("""
    **[ì„¤ì • ë°©ë²•]**
    1. **ë¡œì»¬ ì‹¤í–‰ ì‹œ**: í”„ë¡œì íŠ¸ í´ë” ì•ˆì— `.streamlit` í´ë”ë¥¼ ë§Œë“¤ê³  `secrets.toml` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    2. **ì›¹ ë°°í¬ ì‹œ**: Streamlit Cloud ì„¤ì • í˜ì´ì§€ì˜ **Secrets** ë€ì— í‚¤ë¥¼ ë³µì‚¬í•´ ë„£ìœ¼ì„¸ìš”.
    """)
    st.stop()

# -----------------------------------------------------------------------------
# ë…¸ì…˜ ê³µê°œ ì£¼ì†Œ
PUBLIC_NOTION_DOMAIN = "greation83.notion.site"
PUBLIC_NOTION_URL = f"https://{PUBLIC_NOTION_DOMAIN}/2c1576d96adb80bab598f4232e364f3f?v=2c1576d96adb80bba8dc000cee9827e8"

# ì„ë² ë”© ì„¤ì •
EMBEDDING_MODEL = "models/text-embedding-004"

# =============================================================================
# ì´ˆê¸°í™”
# =============================================================================

st.set_page_config(layout="wide", page_title="ì„¤êµ ë¹„ì„œ Pro (Cloud)")

if GEMINI_API_KEY.startswith("AIza"):
    genai.configure(api_key=GEMINI_API_KEY)
else:
    st.warning("âš ï¸ API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# =============================================================================
# Google Drive í•¨ìˆ˜
# =============================================================================

def get_drive_service():
    """Google Drive API ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„±"""
    try:
        creds = service_account.Credentials.from_service_account_info(
            dict(GDRIVE_SERVICE_ACCOUNT),
            scopes=['https://www.googleapis.com/auth/drive']
        )
        service = build('drive', 'v3', credentials=creds)
        return service
    except Exception as e:
        st.error(f"Google Drive ì—°ê²° ì‹¤íŒ¨: {e}")
        return None


def download_from_drive(service, file_id):
    """Driveì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        request = service.files().get_media(fileId=file_id)
        file_buffer = io.BytesIO()
        downloader = MediaIoBaseDownload(file_buffer, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()
        file_buffer.seek(0)
        return json.load(file_buffer)
    except Exception as e:
        st.warning(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def upload_to_drive(service, data, file_id):
    """Driveì— íŒŒì¼ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°)"""
    try:
        file_buffer = io.BytesIO()
        json_str = json.dumps(data, ensure_ascii=False)
        file_buffer.write(json_str.encode('utf-8'))
        file_buffer.seek(0)
        
        media = MediaIoBaseUpload(file_buffer, mimetype='application/json', resumable=True)
        
        # ê¸°ì¡´ íŒŒì¼ ì—…ë°ì´íŠ¸
        updated_file = service.files().update(
            fileId=file_id,
            media_body=media
        ).execute()
        
        return updated_file['id']
    except Exception as e:
        st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


# =============================================================================
# AI í”„ë¡¬í”„íŠ¸
# =============================================================================

ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ 20ë…„ ì°¨ ì„¤êµí•™ êµìˆ˜ì´ì ì˜ˆí™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì„¤êµ ì´ˆì•ˆì„ **ê¹Šì´ ìˆê²Œ ë¶„ì„**í•˜ì—¬ ì´ ì„¤êµì— í•„ìš”í•œ ì˜ˆí™”ì˜ ì¡°ê±´ì„ ë„ì¶œí•´ì£¼ì„¸ìš”.

## ì„¤êµ ì´ˆì•ˆ:
{draft}

## ë¶„ì„ ìš”ì²­ í•­ëª©:
1. **í•µì‹¬ì£¼ì œ**: ì„¤êµë¥¼ ê´€í†µí•˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ (ëª…ì‚¬í˜•)
2. **ê°ì •ì„ **: ì´ ì„¤êµì˜ ì£¼ëœ ì •ì„œ (ì˜ˆ: ìœ„ë¡œ, ë„ì „, íšŒê°œ, ê°ì‚¬, ê²½ê³ , ìœ ë¨¸)
3. **ì—°ê´€ì„±ê²½**: ì„¤êµì™€ ì—°ê´€ëœ ì„±ê²½ ê¶Œ(Book) ì´ë¦„ (ì˜ˆ: ì°½ì„¸ê¸°, ë§ˆíƒœë³µìŒ)
4. **ì„¤êµìš”ì•½**: ì„¤êµì˜ í•µì‹¬ ë©”ì‹œì§€ë¥¼ 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½

## ì¶œë ¥ í˜•ì‹ (JSON):
{{
    "í•µì‹¬ì£¼ì œ": ["ì£¼ì œ1", "ì£¼ì œ2", ...],
    "ê°ì •ì„ ": ["ê°ì •1", "ê°ì •2"],
    "ì—°ê´€ì„±ê²½": ["ì°½ì„¸ê¸°"],
    "ì„¤êµìš”ì•½": "ìš”ì•½ë¬¸..."
}}
"""

FEEDBACK_PROMPT = """
ë‹¹ì‹ ì€ 20ë…„ ì°¨ ì„¤êµí•™ êµìˆ˜ì´ì, ì²­ì¤‘ì˜ ì‚¶ì„ ë³€í™”ì‹œí‚¤ëŠ” **'ì‹¤ì²œì  ì ìš©(Application)'ì˜ ëŒ€ê°€**ì…ë‹ˆë‹¤.
ì œìê°€ ì‘ì„±í•œ ì„¤êµ ì´ˆì•ˆì„ ê²€í† í•˜ê³ , íŠ¹íˆ **'ì‹¤ì²œì  ì ìš©'ì´ ì•½í•˜ê±°ë‚˜ ì¶”ìƒì ì¸ ë¶€ë¶„ì„ ì•„ì£¼ êµ¬ì²´ì ìœ¼ë¡œ ë³´ì™„**í•´ì£¼ì„¸ìš”.

## ì„¤êµ ì´ˆì•ˆ:
{draft}

## í”¼ë“œë°± ìš”ì²­ í•­ëª©:
1. **ë…¼ë¦¬ì  ì ê²€**: 
   - ë…¼ë¦¬ì  ë¹„ì•½ì´ ìˆëŠ” ë¶€ë¶„ì´ë‚˜ ì„±ê²½ í•´ì„ì˜ ë¬´ë¦¬ìˆ˜ ì ê²€
2. **êµ¬ì²´ì  í–‰ë™ ì œì•ˆ (Action Plan)**: 
   - **(ê°€ì¥ ì¤‘ìš”)** ì„¤êµìì˜ ì ìš©ì´ ì¶”ìƒì ("ì‚¬ë‘í•˜ì", "ë‚˜ì•„ê°€ì", "ì„¬ê¸°ì")ì´ë¼ë©´, ì´ë¥¼ **ì²­ì¤‘ì´ ì˜¤ëŠ˜ ë‹¹ì¥ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ í–‰ë™**ìœ¼ë¡œ ë°”ê¿” ì œì•ˆí•˜ì„¸ìš”.
   - ëœ¬êµ¬ë¦„ ì¡ëŠ” ì´ì•¼ê¸°ëŠ” í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ìƒ, ì¥ì†Œ, ê¸ˆì•¡, í–‰ë™ì„ ëª…ì‹œí•˜ì„¸ìš”.
   - **ë‚˜ìœ ì˜ˆ**: "ì†Œì™¸ëœ ì´ì›ƒì„ ëŒë´…ì‹œë‹¤."
   - **ì¢‹ì€ ì˜ˆ**: "ìš°ë¦¬ ì•„íŒŒíŠ¸ ê²½ë¹„ì›ë¶„ê»˜ ë”°ëœ»í•œ ìŒë£Œìˆ˜ í•œ ë³‘ì„ ê±´ë„¤ë©° 'ê°ì‚¬í•©ë‹ˆë‹¤'ë¼ê³  ì¸ì‚¬í•©ì‹œë‹¤.", "ì˜¤ëŠ˜ í•˜ë£¨ ì»¤í”¼ í•œ ì” ê°’(5,000ì›)ì„ ì•„ê»´ ë¯¸í˜¼ëª¨ ì‹œì„¤ì´ë‚˜ êµ¬í˜¸ ë‹¨ì²´ì— ê¸°ë¶€í•©ì‹œë‹¤."
3. **ê°•ì  ì¹­ì°¬**:
   - ì„¤êµì—ì„œ ê°€ì¥ í›Œë¥­í•œ í†µì°°ì´ë‚˜ í‘œí˜„

## ì¶œë ¥ í˜•ì‹ (JSON):
{{
    "ë…¼ë¦¬ì ê²€": ["ì§€ì ì‚¬í•­1", "ì§€ì ì‚¬í•­2"],
    "ë³´ì™„ì œì•ˆ": ["êµ¬ì²´ì  í–‰ë™ ì œì•ˆ1", "êµ¬ì²´ì  í–‰ë™ ì œì•ˆ2", "êµ¬ì²´ì  í–‰ë™ ì œì•ˆ3"],
    "ê°•ì ": "ì´ ì„¤êµì˜ í›Œë¥­í•œ ì ..."
}}
"""

RECOMMENDATION_PROMPT = """
ë‹¹ì‹ ì€ ì„¤êµ ì‘ì„±ìë¥¼ ë•ëŠ” ì¡°ìˆ˜ì…ë‹ˆë‹¤.
ì„¤êµ ì´ˆì•ˆì˜ ë‚´ìš©ê³¼ íë¦„ì„ ê³ ë ¤í•  ë•Œ, ì•„ë˜ í›„ë³´ ì˜ˆí™”ë“¤ ì¤‘ ê°€ì¥ ì ì ˆí•œ ê²ƒì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.

## ì„¤êµ ìš”ì•½:
{sermon_summary}

## ì„¤êµ ê°ì •ì„ /ì£¼ì œ:
{sermon_tags}

## í›„ë³´ ì˜ˆí™” ëª©ë¡:
{candidates}

## ìš”ì²­:
ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ì˜ˆí™” **10ê°œì—ì„œ 15ê°œ**ë¥¼ ì„ ì •í•˜ì—¬ ì´ìœ ì™€ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.
ë‹¨ìˆœíˆ í‚¤ì›Œë“œê°€ ê°™ì•„ì„œê°€ ì•„ë‹ˆë¼, **ì„¤êµì˜ ë§¥ë½(Context)ì„ ì‚´ë ¤ì¤„ ìˆ˜ ìˆëŠ” ê²ƒ**ì„ ê³ ë¥´ì„¸ìš”.
ì˜ˆë¥¼ ë“¤ì–´, ì„¤êµê°€ 'ê³ ë‚œ ì¤‘ì˜ ì¸ë‚´'ë¥¼ ë‹¤ë£¬ë‹¤ë©´, 'ê°€ë²¼ìš´ ìœ ë¨¸'ë³´ë‹¤ëŠ” 'ê¹Šì´ ìˆëŠ” ê°„ì¦'ì´ë‚˜ 'ì—­ì‚¬ì  ì‚¬ë¡€'ë¥¼ ì¶”ì²œí•˜ì„¸ìš”.

## ì¤‘ìš”: 
- ë°˜ë“œì‹œ í›„ë³´ ì˜ˆí™” ëª©ë¡ì— ìˆëŠ” **'ë²ˆí˜¸(ID)'**ë¥¼ í•¨ê»˜ ì¶œë ¥í•´ì£¼ì„¸ìš”.
- **ë™ì¼í•œ ì„¤êµìì˜ ì˜ˆí™”ëŠ” ìµœëŒ€ 3ê°œ**ê¹Œì§€ë§Œ ì¶”ì²œí•˜ì„¸ìš”. ë‹¤ì–‘í•œ ì¶œì²˜ì˜ ì˜ˆí™”ë¥¼ ì„ ì •í•´ì£¼ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹ (JSON):
{{
    "ì¶”ì²œëª©ë¡": [
        {{
            "ë²ˆí˜¸": 1, 
            "ì œëª©": "ì˜ˆí™” ì œëª©",
            "ì¶”ì²œì´ìœ ": "ì´ ì˜ˆí™”ëŠ” ì„¤êµì˜ [ì–´ë–¤ ë¶€ë¶„]ì—ì„œ [ì–´ë–¤ íš¨ê³¼]ë¥¼ ì¤„ ìˆ˜ ìˆì–´ ì¶”ì²œí•©ë‹ˆë‹¤. (êµ¬ì²´ì ìœ¼ë¡œ)",
            "í™œìš©íŒ": "ì„œë¡  ì˜ˆí™”ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ê²°ë¡ ë¶€ ì ìš© ì§ˆë¬¸ìœ¼ë¡œ ë˜ì§€ê¸° ì¢‹ìŠµë‹ˆë‹¤."
        }},
        ...
    ]
}}
"""

GBS_PROMPT_TEMPLATE = """
## ì—­í•  ì •ì˜ (Role)
ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ ì„±ê²½ êµì¬ ì§‘í•„ê°€ì´ì **{target_dept} ì „ë¬¸ê°€**ì…ë‹ˆë‹¤. 
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ [ì„¤êµ ì´ˆì•ˆ]ì„ ë°”íƒ•ìœ¼ë¡œ, **{target_dept}** êµ¬ì„±ì›ë“¤ì´ ì†Œê·¸ë£¹ì—ì„œ ê¹Šì´ ìˆê²Œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” **'ë§ì¶¤í˜• GBS(Group Bible Study) êµì¬'**ë¥¼ ì œì‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ (Target Audience)
* ëŒ€ìƒ: **{target_dept}** ({age_range})
* íŠ¹ì§•: {dept_characteristics}

## ì‘ì—… ëª©í‘œ (Objective)
ì„¤êµì˜ í•µì‹¬ ë©”ì‹œì§€ë¥¼ í›¼ì†í•˜ì§€ ì•Šìœ¼ë©´ì„œ, {target_dept}ê°€ ì§€ë£¨í•´í•˜ì§€ ì•Šê³  ì‚¶ì— êµ¬ì²´ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” **ë‹¨ í•˜ë‚˜ì˜ ê¹”ë”í•œ êµì¬**ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
**ë³µì¡í•œ ì„œì‹(í‘œ, ë°•ìŠ¤ ë“±)ì„ í”¼í•˜ê³ , ì•„ì´ì½˜(ì´ëª¨ì§€)ê³¼ í…ìŠ¤íŠ¸ë¡œë§Œ êµ¬ì„±í•˜ì—¬ ë³µì‚¬+ë¶™ì—¬ë„£ê¸°ê°€ ì‰½ë„ë¡ ì‘ì„±í•˜ì‹­ì‹œì˜¤.**

## ì¶œë ¥ í˜•ì‹ (Output Format)
ë°˜ë“œì‹œ ì•„ë˜ ëª©ì°¨ì— ë”°ë¼ ì‘ì„±í•˜ë©°, **ì¤‘ë³µëœ ë‚´ìš©ì„ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.** (ë³„ë„ì˜ ìš”ì•½ë³¸ì´ë‚˜ ë…¸ì…˜ í¼ìš© ë²„ì „ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.)

---
### **[ì œëª©: (ì„¤êµ ì œëª©ì„ ì¬ì¹˜ ìˆê²Œ ë³€í˜•)]**

### **1. ğŸ§Š ì•„ì´ìŠ¤ë¸Œë ˆì´í¬ (Ice Break)**
* ì„¤êµ ì£¼ì œì™€ ì—°ê²°ëœ, ë§ˆìŒì„ ì—¬ëŠ” ê°€ë²¼ìš´ ì§ˆë¬¸ 2ê°œ

### **2. ğŸ“– ë§ì”€ ì†ìœ¼ë¡œ (Observation)**
* ë³¸ë¬¸ ê´€ì°° ë° í•´ì„ ì§ˆë¬¸ 3ê°œ (ê¹Šì´ ìˆëŠ” í†µì°° ìœ ë„)

### **3. ğŸƒâ€â™‚ï¸ ì‚¶ìœ¼ë¡œ (Application)**
* **Apply (ì§„ë‹¨):** ë‚˜ì˜ ìƒíƒœë¥¼ ì ê²€í•˜ëŠ” ì§ˆë¬¸ 2~3ê°œ
* **Break (ê¹¨ë‹¬ìŒ):** ë³¸ë¬¸ì´ ì£¼ëŠ” êµí›ˆ í•œ ë¬¸ë‹¨ (4~5ì¤„)
* **Build (ì‹¤ì²œ):** ì´ë²ˆ ì£¼ ë°”ë¡œ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì‹¤ì²œ 3~5ê°œ (ê´€ê³„, ì¬ì •, ì‹œê°„ ë“± êµ¬ì²´ì  ì˜ì—­ ì–¸ê¸‰)
* **Pray (ê¸°ë„):** í•¨ê»˜ ì½ì„ ìˆ˜ ìˆëŠ” ì§§ì€ ê¸°ë„ë¬¸

### **4. ğŸ§  íŒ í€´ì¦ˆ (Pop Quiz)**
* ê°ê´€ì‹ 3ë¬¸ì œ + OX 2ë¬¸ì œ
* **(ì •ë‹µì€ í€´ì¦ˆ ë°”ë¡œ ì•„ë˜ì— ì‘ê²Œ í‘œê¸°)**

### **5. ğŸŒŠ í”Œë¡œì‰ ìœ„í¬ (í•œ ì£¼ê°„ì˜ ë¯¸ì…˜)**
* **ì›”(See):** (ë¯¸ì…˜ ë‚´ìš©)
* **í™”(Speak):** (ë¯¸ì…˜ ë‚´ìš©)
* **ìˆ˜(Cost):** (ë¯¸ì…˜ ë‚´ìš©)
* **ëª©(Listen):** (ë¯¸ì…˜ ë‚´ìš©)
* **ê¸ˆ(Act):** (ë¯¸ì…˜ ë‚´ìš©)
* **í† (Pray):** (ë¯¸ì…˜ ë‚´ìš©)
---

## í†¤ì•¤ë§¤ë„ˆ
* {tone_manner}
* ì„¤ëª…ì¡°ë³´ë‹¤ëŠ” ëŒ€í™”ì²´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ.

## ì„¤êµ ì´ˆì•ˆ:
{draft}
"""

# =============================================================================
# ì„ë² ë”© ê´€ë ¨ í•¨ìˆ˜
# =============================================================================

def load_embeddings_from_drive():
    """Google Driveì—ì„œ ì„ë² ë”© ë¡œë“œ (íŒŒì¼ ID ì§ì ‘ ì‚¬ìš©)"""
    if 'embeddings_cache' in st.session_state and st.session_state['embeddings_cache']:
        return st.session_state['embeddings_cache']
    
    service = get_drive_service()
    if not service:
        return []
    
    # íŒŒì¼ ID ì§ì ‘ ì‚¬ìš©
    data = download_from_drive(service, GDRIVE_FILE_ID)
    if data:
        embeddings = data.get('embeddings', [])
        st.session_state['embeddings_cache'] = embeddings
        return embeddings
    
    return []


def save_embeddings_to_drive(embeddings_data):
    """Google Driveì— ì„ë² ë”© ì €ì¥ (íŒŒì¼ ID ì§ì ‘ ì‚¬ìš©)"""
    service = get_drive_service()
    if not service:
        return False
    
    data = {
        "version": "1.0",
        "model": EMBEDDING_MODEL,
        "count": len(embeddings_data),
        "embeddings": embeddings_data
    }
    
    # íŒŒì¼ ID ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì—…ë°ì´íŠ¸
    result = upload_to_drive(service, data, GDRIVE_FILE_ID)
    
    if result:
        st.session_state['embeddings_cache'] = embeddings_data
        return True
    
    return False


def get_embedding(text, max_retries=3):
    """Gemini ì„ë² ë”© ìƒì„±"""
    for attempt in range(max_retries):
        try:
            result = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=text,
                task_type="retrieval_document"
            )
            return result['embedding']
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                return None
    return None


def get_query_embedding(text):
    """ê²€ìƒ‰ ì¿¼ë¦¬ìš© ì„ë² ë”© ìƒì„±"""
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=text,
            task_type="retrieval_query"
        )
        return result['embedding']
    except Exception as e:
        st.warning(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def cosine_similarity(a, b):
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def create_embedding_text(illust):
    """ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
    parts = [illust.get('title', '')]
    
    if illust.get('summary'):
        parts.append(illust['summary'])
    
    subjects = illust.get('subjects', [])
    if subjects:
        if isinstance(subjects, list):
            parts.append(", ".join(subjects))
        else:
            parts.append(str(subjects))
    
    emotions = illust.get('emotions', [])
    if emotions:
        if isinstance(emotions, list):
            parts.append(", ".join(emotions))
        else:
            parts.append(str(emotions))
    
    return " | ".join(parts)


def semantic_search(query_text, embeddings_data, top_k=30):
    """ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰"""
    if not embeddings_data:
        return []
    
    query_embedding = get_query_embedding(query_text)
    if not query_embedding:
        return []
    
    results = []
    for item in embeddings_data:
        if 'embedding' in item and item['embedding']:
            similarity = cosine_similarity(query_embedding, item['embedding'])
            results.append({
                **{k: v for k, v in item.items() if k != 'embedding'},
                'similarity': similarity
            })
    
    results.sort(key=lambda x: x['similarity'], reverse=True)
    return results[:top_k]


# =============================================================================
# ë…¸ì…˜ ê´€ë ¨ í•¨ìˆ˜
# =============================================================================

@st.cache_data(ttl=3600)
def fetch_all_illustrations_from_notion():
    """ë…¸ì…˜ì—ì„œ ëª¨ë“  ì˜ˆí™” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    headers = {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }
    
    results = []
    has_more = True
    next_cursor = None

    while has_more:
        try:
            payload = {"filter": {"property": "ì¢…ë¥˜", "select": {"equals": "ì˜ˆí™”"}}, "page_size": 100}
            if next_cursor:
                payload["start_cursor"] = next_cursor
            
            response = requests.post(url, headers=headers, json=payload)
            if response.status_code != 200:
                break
            
            data = response.json()
            results.extend(data.get('results', []))
            has_more = data.get('has_more', False)
            next_cursor = data.get('next_cursor', None)
        except:
            break
    
    processed_data = []
    for page in results:
        props = page.get('properties', {})
        title_prop = props.get('title', {}).get('title', [])
        title = title_prop[0].get('plain_text', "") if title_prop else ""
        
        subjects = []
        subject_prop = props.get('ì£¼ì œ', {})
        prop_type = subject_prop.get('type')
        if prop_type == 'multi_select':
            subjects = [item.get('name', "") for item in subject_prop.get('multi_select', [])]
        elif prop_type == 'rich_text':
            text_list = subject_prop.get('rich_text', [])
            if text_list:
                raw_text = text_list[0].get('plain_text', "")
                subjects = [s.strip() for s in raw_text.split(',') if s.strip()]

        emotions = [item.get('name', "") for item in props.get('ê°ì •í†¤', {}).get('multi_select', [])]
        
        summary_prop = props.get('ì˜ˆí™”ìš”ì•½', {}).get('rich_text', [])
        summary = summary_prop[0].get('plain_text', "") if summary_prop else ""
        
        source_url = props.get('URL', {}).get('url', "")
        
        preacher_prop = props.get('ì„¤êµì', {})
        preacher = ""
        if preacher_prop.get('type') == 'select' and preacher_prop.get('select'):
            preacher = preacher_prop['select'].get('name', "")
        elif preacher_prop.get('type') == 'rich_text':
            text_list = preacher_prop.get('rich_text', [])
            if text_list:
                preacher = text_list[0].get('plain_text', "")
            
        processed_data.append({
            "id": page['id'],
            "title": title,
            "subjects": subjects,
            "emotions": emotions,
            "summary": summary,
            "url": page.get('url', ""),
            "source_url": source_url,
            "preacher": preacher
        })
    return processed_data


def generate_all_embeddings(notion_data, progress_placeholder):
    """ëª¨ë“  ì˜ˆí™”ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± (ìµœì´ˆ 1íšŒ)"""
    embeddings_data = []
    total = len(notion_data)
    
    for i, item in enumerate(notion_data):
        progress = (i + 1) / total
        progress_placeholder.progress(progress, text=f"ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘... {i+1}/{total} ({progress:.0%})")
        
        embed_text = create_embedding_text(item)
        embedding = get_embedding(embed_text)
        
        if embedding:
            embeddings_data.append({
                "id": item['id'],
                "title": item['title'],
                "summary": item['summary'],
                "subjects": item['subjects'],
                "emotions": item['emotions'],
                "source_url": item['source_url'],
                "preacher": item.get('preacher', ''),
                "embedding": embedding
            })
        
        if (i + 1) % 30 == 0:
            time.sleep(1)
    
    return embeddings_data


def sync_embeddings_with_notion(notion_data, embeddings_data):
    """ë…¸ì…˜ ë°ì´í„°ì™€ ì„ë² ë”© ë™ê¸°í™” (ìƒˆ ì˜ˆí™”ë§Œ ì¶”ê°€)"""
    existing_ids = {item['id'] for item in embeddings_data}
    new_items = [item for item in notion_data if item['id'] not in existing_ids]
    
    if not new_items:
        return embeddings_data, 0
    
    new_embeddings = []
    for item in new_items:
        embed_text = create_embedding_text(item)
        embedding = get_embedding(embed_text)
        
        if embedding:
            new_embeddings.append({
                "id": item['id'],
                "title": item['title'],
                "summary": item['summary'],
                "subjects": item['subjects'],
                "emotions": item['emotions'],
                "source_url": item['source_url'],
                "preacher": item.get('preacher', ''),
                "embedding": embedding
            })
        
        time.sleep(0.1)
    
    updated_data = embeddings_data + new_embeddings
    
    if new_embeddings:
        save_embeddings_to_drive(updated_data)
    
    return updated_data, len(new_embeddings)


# =============================================================================
# ê¸°íƒ€ í•¨ìˆ˜
# =============================================================================

def get_gemini_response(prompt, model_name='gemini-2.5-flash'):
    """Gemini API í˜¸ì¶œ (ì¼ë°˜ í…ìŠ¤íŠ¸ ë°˜í™˜)"""
    try:
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
        }
        model = genai.GenerativeModel(model_name=model_name, generation_config=generation_config)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return None


def get_gemini_json(prompt):
    """Gemini API í˜¸ì¶œ (JSON ë°˜í™˜)"""
    text = get_gemini_response(prompt)
    if text:
        match = re.search(r'\{[\s\S]*\}', text)
        if match:
            try:
                return json.loads(match.group())
            except: 
                pass
    return None


def convert_to_public_url(page_id):
    if not page_id:
        return PUBLIC_NOTION_URL
    clean_id = page_id.replace("-", "")
    return f"https://{PUBLIC_NOTION_DOMAIN}/{clean_id}"


def extract_start_time(url):
    try:
        parsed = urlparse(url)
        qs = parse_qs(parsed.query)
        if 't' in qs:
            return int(qs['t'][0])
    except:
        pass
    return 0


@st.cache_data(ttl=3600)
def fetch_page_content(page_id):
    """íŠ¹ì • í˜ì´ì§€ì˜ ë³¸ë¬¸(Block) ë‚´ìš©ì„ ê°€ì ¸ì™€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    headers = {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }
    
    content_text = ""
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            blocks = response.json().get('results', [])
            for block in blocks:
                b_type = block.get('type')
                text_content = ""
                
                if b_type in ['paragraph', 'heading_1', 'heading_2', 'heading_3', 'bulleted_list_item', 'numbered_list_item', 'callout', 'quote']:
                    rich_text = block.get(b_type, {}).get('rich_text', [])
                    for rt in rich_text:
                        text_content += rt.get('plain_text', "")
                    
                    if text_content:
                        if b_type == 'heading_1':
                            content_text += f"\n# {text_content}\n"
                        elif b_type == 'heading_2':
                            content_text += f"\n## {text_content}\n"
                        elif b_type == 'heading_3':
                            content_text += f"\n### {text_content}\n"
                        elif b_type == 'bulleted_list_item':
                            content_text += f"â€¢ {text_content}\n"
                        elif b_type == 'numbered_list_item':
                            content_text += f"1. {text_content}\n"
                        elif b_type == 'quote':
                            content_text += f"\n> {text_content}\n"
                        else:
                            content_text += f"{text_content}\n\n"
        else:
            return "(ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)"
    except:
        return "(ë³¸ë¬¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ)"
    return content_text if content_text else "(ë³¸ë¬¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.)"


# =============================================================================
# ë©”ì¸ UI
# =============================================================================

def main():
    # Google Driveì—ì„œ ì„ë² ë”© ë¡œë“œ
    embeddings_data = load_embeddings_from_drive()
    needs_initial_setup = len(embeddings_data) == 0
    
    with st.sidebar:
        st.markdown("### ğŸ•Šï¸ Sermon Assistant Pro")
        st.info("ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ v2.0\n(Google Drive ì €ì¥)")
        st.markdown("---")
        st.link_button("ğŸ“š ì „ì²´ ì˜ˆí™” ë„ì„œê´€(Notion) ê°€ê¸°", PUBLIC_NOTION_URL)
        
        st.caption(f"ğŸ“Š ì„ë² ë”© ë³´ìœ : {len(embeddings_data)}ê°œ")
        
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            if 'embeddings_cache' in st.session_state:
                del st.session_state['embeddings_cache']
            st.rerun()

    st.title("ğŸ•Šï¸ ì„¤êµ ë¹„ì„œ: ì˜ˆí™” & GBS ë©”ì´ì»¤")
    st.markdown("ì„¤êµ ì´ˆì•ˆì„ ë„£ìœ¼ë©´ **ì˜ˆí™” ì¶”ì²œ, ì„¤êµ í´ë¦¬ë‹‰, ê·¸ë¦¬ê³  ì†Œê·¸ë£¹ êµì¬**ê¹Œì§€ í•œ ë²ˆì— ì œì‘í•©ë‹ˆë‹¤.")

    # ==========================================================================
    # ìµœì´ˆ ì‹¤í–‰ ì‹œ ì„ë² ë”© ìƒì„±
    # ==========================================================================
    if needs_initial_setup:
        st.warning("âš ï¸ ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì´ˆ 1íšŒ ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.info("ì˜ˆí™” 5,000ê°œ ê¸°ì¤€ ì•½ 5-10ë¶„ ì†Œìš”ë©ë‹ˆë‹¤. ìƒì„±ëœ ë°ì´í„°ëŠ” Google Driveì— ì €ì¥ë˜ì–´ ëª¨ë“  ì‚¬ìš©ìê°€ ê³µìœ í•©ë‹ˆë‹¤.")
        
        if st.button("ğŸš€ ì„ë² ë”© ìƒì„± ì‹œì‘", type="primary"):
            st.markdown("---")
            
            with st.spinner("ğŸ“š ë…¸ì…˜ì—ì„œ ì˜ˆí™” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                notion_data = fetch_all_illustrations_from_notion()
            
            if not notion_data:
                st.error("ë…¸ì…˜ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                return
            
            st.success(f"âœ… {len(notion_data)}ê°œ ì˜ˆí™” ë¡œë“œ ì™„ë£Œ!")
            
            st.markdown("### ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘...")
            progress_bar = st.empty()
            
            embeddings_data = generate_all_embeddings(notion_data, progress_bar)
            
            st.markdown("### ğŸ’¾ Google Driveì— ì €ì¥ ì¤‘...")
            if save_embeddings_to_drive(embeddings_data):
                st.success(f"âœ… {len(embeddings_data)}ê°œ ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")
                st.balloons()
                time.sleep(2)
                st.rerun()
            else:
                st.error("Google Drive ì €ì¥ ì‹¤íŒ¨")
        
        return
    
    # ==========================================================================
    # ì •ìƒ UI
    # ==========================================================================
    with st.expander("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ"):
        st.markdown("""
        1. **ì„¤êµ ì…ë ¥**: ì„¤êµ ì›ê³ ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.
        2. **ë¶€ì„œ ì„ íƒ**: êµì¬ë¥¼ ë§Œë“¤ ëŒ€ìƒì„ ì„ íƒí•˜ì„¸ìš” (ì²­ë…„ë¶€ ë“±).
        3. **ë¶„ì„ ì‹œì‘**: ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ëª¨ë“  ì‘ì—…ì´ ìë™ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
        
        ---
        **ğŸ†• v2.0 ì—…ë°ì´íŠ¸**: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ + Google Drive ì €ì¥!
        """)

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ“ ì„¤êµ ì´ˆì•ˆ ë° ì„¤ì •")
        target_dept = st.selectbox("êµì¬ ì œì‘ ëŒ€ìƒ (ë¶€ì„œ)", ["ì²­ë…„ë¶€", "ì¥ë…„ë¶€", "ì¤‘ê³ ë“±ë¶€", "ìœ ì´ˆë“±ë¶€"])
        sermon_draft = st.text_area("ì„¤êµ ë³¸ë¬¸ ë¶™ì—¬ë„£ê¸°", height=600, placeholder="ë³¸ë¬¸ì„ ì…ë ¥í•˜ë©´ ì˜ˆí™”ë„ ì°¾ê³  êµì¬ë„ ë§Œë“¤ì–´ë“œë¦½ë‹ˆë‹¤.")
        
        analyze_btn = st.button("ğŸš€ ë¶„ì„ ë° êµì¬ ìƒì„± ì‹œì‘", type="primary")

    if analyze_btn and sermon_draft:
        with col2:
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
            
            # 0. ì„ë² ë”© ë™ê¸°í™”
            with st.status("ğŸ“š ì˜ˆí™” ë°ì´í„° ë™ê¸°í™” ì¤‘...") as status:
                notion_data = fetch_all_illustrations_from_notion()
                embeddings_data, new_count = sync_embeddings_with_notion(notion_data, embeddings_data)
                
                if new_count > 0:
                    status.update(label=f"âœ… {new_count}ê°œ ìƒˆ ì˜ˆí™” ì„ë² ë”© ì¶”ê°€!", state="complete")
                else:
                    status.update(label=f"âœ… ì˜ˆí™” {len(embeddings_data)}ê°œ ì¤€ë¹„ ì™„ë£Œ", state="complete")
            
            # 1. ì„¤êµ ë¶„ì„
            with st.status("ğŸ” ì„¤êµë¥¼ ë¶„ì„í•˜ê³  ì£¼ì œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...") as status:
                analysis_result = get_gemini_json(ANALYSIS_PROMPT.format(draft=sermon_draft))
                if not analysis_result:
                    st.error("ë¶„ì„ ì‹¤íŒ¨: API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    return
                status.update(label="âœ… ì„¤êµ ë¶„ì„ ì™„ë£Œ!", state="complete")
            
            # 2. ì˜ˆí™” ì¶”ì²œ (ì„ë² ë”© ê¸°ë°˜)
            with st.status("ğŸ“š ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ì˜ˆí™”ë¥¼ ì°¾ìŠµë‹ˆë‹¤...") as status:
                search_query = analysis_result.get('ì„¤êµìš”ì•½', '')
                if analysis_result.get('í•µì‹¬ì£¼ì œ'):
                    search_query += " " + " ".join(analysis_result['í•µì‹¬ì£¼ì œ'])
                if analysis_result.get('ê°ì •ì„ '):
                    search_query += " " + " ".join(analysis_result['ê°ì •ì„ '])
                
                top_candidates = semantic_search(search_query, embeddings_data, top_k=30)

                recommendation_result = None
                if top_candidates:
                    candidates_text = ""
                    for idx, cand in enumerate(top_candidates):
                        preacher_info = f" | ì„¤êµì: {cand.get('preacher', 'ë¯¸ìƒ')}" if cand.get('preacher') else ""
                        candidates_text += f"{idx+1}. ì œëª©: {cand['title']} | ìš”ì•½: {cand.get('summary', '')} | íƒœê·¸: {cand.get('subjects', [])}{preacher_info}\n"
                    
                    curation_prompt = RECOMMENDATION_PROMPT.format(
                        sermon_summary=analysis_result['ì„¤êµìš”ì•½'],
                        sermon_tags=f"ì£¼ì œ: {analysis_result['í•µì‹¬ì£¼ì œ']}, ê°ì •: {analysis_result['ê°ì •ì„ ']}",
                        candidates=candidates_text
                    )
                    recommendation_result = get_gemini_json(curation_prompt)
                status.update(label="âœ… ì˜ˆí™” ì¶”ì²œ ì™„ë£Œ!", state="complete")

            # 3. í”¼ë“œë°± & GBS ìƒì„±
            with st.status(f"âœï¸ {target_dept} ë§ì¶¤í˜• êµì¬ì™€ í”¼ë“œë°±ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...") as status:
                feedback_result = get_gemini_json(FEEDBACK_PROMPT.format(draft=sermon_draft))
                
                if target_dept == "ì²­ë…„ë¶€":
                    age_range = "20~30ëŒ€ ëŒ€í•™ìƒ/ì§ì¥ì¸"
                    dept_characteristics = "ê¶Œìœ„ì ì¸ ê°€ë¥´ì¹¨ë³´ë‹¤ ì§„ì •ì„± ìˆëŠ” ë‚˜ëˆ” ì„ í˜¸, êµ¬ì²´ì  ì‚¶ì˜ ì ìš© ì›í•¨"
                    tone_manner = "ì¹œê·¼í•˜ê³  ìœ„íŠ¸ ìˆìœ¼ë©´ì„œë„ í•µì‹¬ì„ ì°Œë¥´ëŠ” ì–´ì¡° (MZ/Alpha ê°ì„±)"
                elif target_dept == "ì¥ë…„ë¶€":
                    age_range = "40~60ëŒ€ ì„±ì¸"
                    dept_characteristics = "ì‚¶ì˜ ì—°ë¥œì´ ìˆìœ¼ë©° ê°€ì •ê³¼ ì§ì¥ì˜ ë¬´ê²Œë¥¼ ê²¬ë””ëŠ” ì„¸ëŒ€, ê¹Šì€ ìœ„ë¡œì™€ í†µì°° í•„ìš”"
                    tone_manner = "ì •ì¤‘í•˜ê³  ê¹Šì´ ìˆìœ¼ë©° ëª©íšŒì  ëŒë´„ì´ ëŠê»´ì§€ëŠ” ì–´ì¡°"
                elif target_dept == "ì¤‘ê³ ë“±ë¶€":
                    age_range = "10ëŒ€ ì²­ì†Œë…„"
                    dept_characteristics = "í•™ì—… ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ì •ì²´ì„± ê³ ë¯¼, ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë©”ì‹œì§€ ì„ í˜¸"
                    tone_manner = "ì—ë„ˆì§€ ë„˜ì¹˜ê³  ì§§ê³  ê°„ê²°í•œ ì–´ì¡°"
                else:
                    age_range = "ì´ˆë“±í•™ìƒ"
                    dept_characteristics = "í™œë™ì ì´ê³  ì‰¬ìš´ ì–¸ì–´ í•„ìš”, ìŠ¤í† ë¦¬í…”ë§ ì¤‘ìš”"
                    tone_manner = "ë‹¤ì •í•˜ê³  ì‰¬ìš´ ì„ ìƒë‹˜ ë§íˆ¬ (ì¡´ëŒ“ë§ ì‚¬ìš©)"

                gbs_prompt = GBS_PROMPT_TEMPLATE.format(
                    target_dept=target_dept,
                    age_range=age_range,
                    dept_characteristics=dept_characteristics,
                    tone_manner=tone_manner,
                    draft=sermon_draft
                )
                
                gbs_content = get_gemini_response(gbs_prompt)
                status.update(label="âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!", state="complete")

            # === ê²°ê³¼ íƒ­ ===
            tab1, tab2, tab3 = st.tabs(["ğŸ¤– AI ì¶”ì²œ ì˜ˆí™”", "âœï¸ GBS êµì¬ (ë³µì‚¬ìš©)", "ğŸ‘¨â€ğŸ« ì„¤êµ í´ë¦¬ë‹‰"])
            
            with tab1:
                st.info(f"**ğŸ’¡ ì„¤êµ ìš”ì•½:** {analysis_result.get('ì„¤êµìš”ì•½', '')}")
                if recommendation_result and recommendation_result.get('ì¶”ì²œëª©ë¡'):
                    for idx, rec in enumerate(recommendation_result['ì¶”ì²œëª©ë¡']):
                        original_data = None
                        if 'ë²ˆí˜¸' in rec and isinstance(rec['ë²ˆí˜¸'], int):
                            try:
                                candidate_index = rec['ë²ˆí˜¸'] - 1
                                if 0 <= candidate_index < len(top_candidates):
                                    original_data = top_candidates[candidate_index]
                            except:
                                pass
                        if not original_data:
                            original_data = next((item for item in top_candidates if item["title"] == rec["ì œëª©"]), None)

                        with st.container():
                            preacher_badge = f" `{original_data.get('preacher', '')}`" if original_data and original_data.get('preacher') else ""
                            st.markdown(f"#### ğŸ“Œ {rec['ì œëª©']}{preacher_badge}")
                            st.write(f"**ğŸ—£ï¸ ì¶”ì²œ ì´ìœ :** {rec['ì¶”ì²œì´ìœ ']}")
                            st.caption(f"**ğŸ’¡ í™œìš© íŒ:** {rec['í™œìš©íŒ']}")
                            if original_data:
                                if 'similarity' in original_data:
                                    st.caption(f"ğŸ“Š ì˜ë¯¸ ìœ ì‚¬ë„: {original_data['similarity']:.2%}")
                                
                                with st.expander("ğŸ“– ì˜ˆí™” ë³¸ë¬¸ & ì˜ìƒ ë³´ê¸°", expanded=(idx == 0)):
                                    with st.spinner("ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                                        if original_data.get('source_url'):
                                            start_time = extract_start_time(original_data['source_url'])
                                            st.markdown(f"**ğŸ“º ê´€ë ¨ ì„¤êµ ì˜ìƒ (ì‹œì‘ ì‹œê°„: {start_time}ì´ˆ)**")
                                            st.video(original_data['source_url'], start_time=start_time)
                                            
                                            st.info("""
                                            ğŸ’¡ **ì˜ˆí™”ì™€ ì˜ìƒ ì‹œê°„ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ”**
                                            1. ì˜ìƒ ë§í¬ë¥¼ ëˆ„ë¥¸ í›„ 
                                            2. ì¡°íšŒ ìˆ˜ê°€ ì í˜€ ìˆëŠ” ë°•ìŠ¤ ì•„ë˜ ìª½ **"ë”ë³´ê¸°"** í´ë¦­
                                            3. ë°•ìŠ¤ ë°‘ì— íŒŒë€ ê¸€ì”¨ë¡œ **"ìŠ¤í¬ë¦½íŠ¸ í‘œì‹œ"**ë¥¼ í´ë¦­
                                            4. `ctrl+F` ë¥¼ ëˆŒëŸ¬ ì˜ˆí™” ë‚´ìš©ì˜ ë‹¨ì–´ë“¤ì„ ê²€ìƒ‰í•˜ë©´ ì˜ˆí™”ë¥¼ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
                                            """)
                                            
                                        st.divider()
                                        content_text = fetch_page_content(original_data['id'])
                                        st.markdown(content_text)
                                        st.divider()
                                        public_url = convert_to_public_url(original_data['id'])
                                        st.link_button("ğŸ”— ë…¸ì…˜ í˜ì´ì§€ ì—´ê¸°", public_url)
                            st.divider()
                else:
                    st.write("ì¶”ì²œëœ ì˜ˆí™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab2:
                st.markdown(f"### ğŸ“– {target_dept} ë§ì¶¤í˜• ì†Œê·¸ë£¹ êµì¬")
                st.info("ìš°ì¸¡ ìƒë‹¨ì˜ 'Copy' ì•„ì´ì½˜ì„ ëˆ„ë¥´ë©´ ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                st.code(gbs_content, language='markdown') 
                st.markdown("---")
                st.markdown(gbs_content) 

            with tab3:
                if feedback_result:
                    st.markdown("### ğŸ“¢ ì„¤êµ ë…¼ë¦¬ & ì „ë‹¬ë ¥ í´ë¦¬ë‹‰")
                    st.success(f"**ğŸ‘ ê°•ì :** {feedback_result.get('ê°•ì ', 'í›Œë¥­í•œ ì„¤êµì…ë‹ˆë‹¤.')}")
                    st.markdown("#### âš ï¸ ë…¼ë¦¬ì  ì ê²€")
                    for point in feedback_result.get('ë…¼ë¦¬ì ê²€', []):
                        st.markdown(f"- {point}")
                    st.markdown("#### ğŸƒâ€â™‚ï¸ êµ¬ì²´ì  í–‰ë™ ì œì•ˆ (Action Plan)")
                    for point in feedback_result.get('ë³´ì™„ì œì•ˆ', []):
                        st.markdown(f"- {point}")


if __name__ == "__main__":
    main()
